** Supply Chain Management
This project focuses on analyzing supply chain management data to uncover insights that improve efficiency, cost management, and decision-making. The dataset used contained 100 records and 24 features, covering aspects such as product type, lead time, revenue, costs, routes, and distribution channels.

* Through exploratory data analysis (EDA), the project examined:

1. Revenue trends across different lead times, routes, and product categories.
2. Cost analysis, identifying variations by product type and distribution path.
3. Route performance, evaluating revenue distribution and profitability.
4. Product comparisons, highlighting which categories contribute most to revenue and which incur higher costs.

* Key findings revealed that:

1. Certain routes consistently generate higher revenue, suggesting optimization opportunities in logistics.
2. Product type significantly influences both revenue and cost, making product-specific strategies crucial.
3. Shorter lead times correlate with higher revenue generation, indicating efficiency in supply chain flow.

Key Findings and Analyses
1. Total Shipping Costs by Supplier
The analysis aggregates the total shipping costs for each supplier. This insight is crucial for identifying which suppliers incur the highest shipping expenses, which is an important metric for cost management and negotiation.

Code Used: df.groupby("Supplier name")["Shipping costs"].sum()

Purpose: To calculate and compare the total shipping costs for each supplier.

2. Defect Rates by Inspection Result
This analysis calculates the average defect rate for each inspection result category (Pass, Fail, Pending). This helps in understanding the quality control process and identifying trends in product defects.

* Code Used: df.groupby("Inspection results")["Defect rates"].mean()
* Purpose: To determine the average defect rate for products based on their inspection outcome.

3. Most Common Transportation Modes
This part of the analysis identifies the most frequently used transportation modes by counting the occurrences of each mode and sorting them in descending order.

* Code Used: df.groupby("Transportation modes").size().sort_values(ascending=False)
* Purpose: To understand the logistics and transportation patterns within the supply chain.

4. Cost vs. Revenue Analysis
A scatter plot is used to visualize the relationship between revenue and costs, with data points colored by product type. This helps to check if higher costs are associated with higher revenue and if different product categories show distinct patterns. The analysis also computes the correlation coefficient between these two variables.

* Code Used: sns.scatterplot(x="Revenue generated", y="Costs", hue="Product type", data=df) and df["Revenue generated"].corr(df["Costs"])
* Purpose: To explore the relationship between the cost of a product and the revenue it generates, and to identify product categories that may have unique cost-revenue dynamics.

5. Distribution of Key Numerical Variables
The project uses both histograms and boxplots to visualize the distribution and statistical summary of key numerical columns such as Costs, Lead time, Stock levels, and Shipping times.

* Histograms: Shows the frequency distribution of each variable to identify the data's central tendency and spread.
* Boxplots: Provides a five-number summary (minimum, first quartile, median, third quartile, and maximum) and helps in identifying potential outliers.
* Code Used: sns.histplot(...) and sns.boxplot(...) within a loop.
* Purpose: To get a quick statistical overview of key performance indicators and identify any anomalies.

6. Correlation Heatmap
A correlation heatmap is generated to visualize the relationships between all numerical variables in the dataset. This helps in quickly identifying which pairs of variables have strong positive or negative correlations.

* Code Used: sns.heatmap(numeric_df.corr(), annot=True, cmap='viridis')
* Purpose: To understand the multi-variate relationships and dependencies within the data.

7. Automated Data Profiling Report
The project also includes an automated data profiling report generated by the ydata-profiling library. This report is a comprehensive overview of the dataset's structure, quality, and statistical properties.

** Key Sections of the Report:
* Overview: Summarizes the number of variables, observations, missing values, and duplicate rows.
* Variables: Provides a detailed profile for each column, including its type, descriptive statistics, and a visualization of its distribution.
* Interactions: Explores relationships between numerical variables through visualizations.
* Correlations: Displays a heatmap of various correlation coefficients (e.g., Pearson, Spearman) to show linear and monotonic relationships.
* Code Used: profile = ProfileReport(df, ...) and profile.to_file(...)
* Purpose: To provide a quick and thorough overview of the dataset without manual, cell-by-cell analysis.
